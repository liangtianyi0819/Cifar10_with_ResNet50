{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS767Assignment9_Question1&2.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGkOiO2UN053"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, Activation, Input, Add, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, ZeroPadding2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed():\n",
        "  InitSeed = 767\n",
        "  tf.random.set_seed(InitSeed)\n",
        "  np.random.seed( InitSeed)\n",
        "\n",
        "\n",
        "def one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "\n",
        "\n",
        "tf.config.run_functions_eagerly(True)\n",
        "(x_train_full, y_train_full), (x_test, y_test) = cifar10.load_data()\n",
        "x_train, x_valid = x_train_full[:-5000]/255, x_train_full[-5000:]/255\n",
        "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
        "x_train = x_train[..., np.newaxis]\n",
        "x_valid = x_valid[..., np.newaxis]\n",
        "x_test = x_test[..., np.newaxis]\n",
        "\n",
        "y_train = one_hot(y_train, 10).T\n",
        "y_valid = one_hot(y_valid, 10).T\n",
        "y_test = one_hot(y_test, 10).T\n",
        "print (\"X_train shape: \" + str(x_train.shape)  + \n",
        "    \"\\nY_train shape: \" + str(y_train.shape) + \n",
        "    \"\\nX_test shape: \" + str(x_test.shape)  + \n",
        "    \"\\nY_test shape: \" + str(y_test.shape)  +\n",
        "    \"\\nX_valid shape: \" + str(x_valid.shape) + \n",
        "    \"\\nY_valid shape: \" + str(y_valid.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQAIGSinmZ8p",
        "outputId": "38df8d3b-28de-4465-bd2a-f0e67e4c2073"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (45000, 32, 32, 3, 1)\n",
            "Y_train shape: (45000, 10)\n",
            "X_test shape: (10000, 32, 32, 3, 1)\n",
            "Y_test shape: (10000, 10)\n",
            "X_valid shape: (5000, 32, 32, 3, 1)\n",
            "Y_valid shape: (5000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "def block(X, filters, first_block=False):\n",
        "  \"\"\"\n",
        "  X: input\n",
        "  filters: List, dim of filters in [f1, f2, f3]\n",
        "  first_block: Bool, if this block is the first block of this big \"layer\"\n",
        "\n",
        "  return: the output X went through all layers in this block\n",
        "  \"\"\"\n",
        "  # Receive filter dimension information\n",
        "  f1, f2, f3 = filters\n",
        "  output_cut = X\n",
        "\n",
        "  # By using functional API\n",
        "  # First layer\n",
        "  if first_block: \n",
        "    output_ = Conv2D(filters=f1, kernel_size=(1,1), strides=(2,2), padding='valid')(X)\n",
        "  else:\n",
        "    output_ = Conv2D(filters=f1, kernel_size=(1,1), strides=(1,1), padding='valid')(X)\n",
        "  output_ = BatchNormalization(axis=3)(output_)\n",
        "  output_ = Activation('relu')(output_)\n",
        "  \n",
        "  # Second layer\n",
        "  output_ = Conv2D(filters=f2, kernel_size=(3,3), strides=(1,1), padding='same')(output_)\n",
        "  output_ = BatchNormalization(axis=3)(output_)\n",
        "  output_ = Activation('relu')(output_)\n",
        "\n",
        "  # Third layer\n",
        "  output_ = Conv2D(filters=f3, kernel_size=(1,1), strides=(1,1), padding='valid')(output_)\n",
        "  output_ = BatchNormalization(axis=3)(output_)\n",
        "\n",
        "  if first_block:\n",
        "    output_cut = Conv2D(filters=f3, kernel_size=(1,1), strides=(2,2), padding='valid')(output_cut)\n",
        "    output_cut = BatchNormalization(axis=3)(output_cut)\n",
        "\n",
        "  # \"Addition step\" - skip-connection value merges with main path\n",
        "  # NOTE: both values have same dimensions at this point, so no operation is required to match dimensions\n",
        "  output_ = Add()([output_, output_cut])\n",
        "  output_ = Activation('relu')(output_)\n",
        "\n",
        "  return output_"
      ],
      "metadata": {
        "id": "io0rQqWKmZ-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start creating the network\n",
        "# Since cifar10 is 32x32x3, 10 classes output,\n",
        "def resNet50(dim=(32,32,3), label=10):\n",
        "  # Receive input\n",
        "  X = Input(dim)\n",
        "  output_ = ZeroPadding2D((3, 3))(X)\n",
        "  \n",
        "  # ================ 7x7, 64, stride 2 ================ \n",
        "  output_ = Conv2D(64, (7, 7), strides = (2, 2))(output_)\n",
        "  output_ = BatchNormalization(axis = 3)(output_)\n",
        "  output_ = Activation('relu')(output_)\n",
        "\n",
        "  # ============= 3x3 max pool, stride 2 =============\n",
        "  output_ = MaxPooling2D((3, 3), strides=(2, 2))(output_)\n",
        "\n",
        "  # ======================= Blocks =======================\n",
        "  \"\"\"\n",
        "  |1 x 1, 64.|\n",
        "  |3 x 3, 64.| X 3\n",
        "  |1 x 1, 256|\"\"\"\n",
        "  output_ = block(output_, filters=[64, 64, 256], first_block=True)\n",
        "  output_ = block(output_, filters=[64, 64, 256], first_block=False)\n",
        "  output_ = block(output_, filters=[64, 64, 256], first_block=False)\n",
        "\n",
        "  \"\"\"\n",
        "  |1 x 1, 128|\n",
        "  |3 x 3, 128| X 4\n",
        "  |1 x 1, 512|\n",
        "  \"\"\"\n",
        "  output_ = block(output_, filters=[128, 128, 512], first_block=True)\n",
        "  for i in range(3):\n",
        "    output_ = block(output_, filters=[128, 128, 512], first_block=False)\n",
        "\n",
        "  \"\"\"\n",
        "  |1 x 1, 256.|\n",
        "  |3 x 3, 256.| X 6\n",
        "  |1 x 1, 1024|\n",
        "  \"\"\"\n",
        "  output_ = block(output_, filters=[256, 256, 1024], first_block=True)\n",
        "  for i in range(5):\n",
        "    output_ = block(output_, filters=[256, 256, 1024], first_block=False)\n",
        "\n",
        "  \"\"\"\n",
        "  |1 x 1, 512.|\n",
        "  |3 x 3, 512.| X 3\n",
        "  |1 x 1, 2048|\n",
        "  \"\"\"\n",
        "  output_ = block(output_, filters=[512, 512, 2048], first_block=True)\n",
        "  output_ = block(output_, filters=[512, 512, 2048], first_block=False)\n",
        "  output_ = block(output_, filters=[512, 512, 2048], first_block=False)\n",
        "\n",
        "  # average pooling, softmax\n",
        "  output_ = AveragePooling2D((2, 2), padding='same')(output_)\n",
        "  output_ = Flatten()(output_)\n",
        "  output_ = Dense(label, activation='softmax', )(output_)\n",
        "\n",
        "  # Aggregate as a model\n",
        "  model = Model(inputs=X, outputs=output_)\n",
        "  return model"
      ],
      "metadata": {
        "id": "-6hdBfKcmaAo"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed()\n",
        "model = resNet50(dim=(32, 32, 3), label=10)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "B1Lmlr26maCz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x0kfFwfuumz",
        "outputId": "e9583dfc-1fc3-45de-9720-ff18fcd0b7d3"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py:265: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
            "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 323s 229ms/step - loss: 2.3738 - accuracy: 0.2708 - val_loss: 1.8962 - val_accuracy: 0.3276\n",
            "Epoch 2/5\n",
            "1407/1407 [==============================] - 322s 229ms/step - loss: 2.2576 - accuracy: 0.2846 - val_loss: 2.6578 - val_accuracy: 0.2084\n",
            "Epoch 3/5\n",
            "1407/1407 [==============================] - 321s 228ms/step - loss: 2.3133 - accuracy: 0.2504 - val_loss: 12.5751 - val_accuracy: 0.2676\n",
            "Epoch 4/5\n",
            "1407/1407 [==============================] - 320s 228ms/step - loss: 1.8977 - accuracy: 0.3641 - val_loss: 3.8347 - val_accuracy: 0.1540\n",
            "Epoch 5/5\n",
            "1407/1407 [==============================] - 319s 227ms/step - loss: 1.9654 - accuracy: 0.3689 - val_loss: 3.3166 - val_accuracy: 0.3242\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f8c3248d0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    }
  ]
}